
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Exercise:Vectorization - Ufldl</title>
<link rel="stylesheet" href="/stanford-ufldl/archive/wiki/skins/common/shared.css" media="screen"/>
<link rel="stylesheet" href="/stanford-ufldl/archive/wiki/skins/monobook/main.css" media="screen"/>

</head>

<body class="mediawiki ltr ns-0 ns-subject page-Exercise_Vectorization skin-monobook">
<div id="globalWrapper">
<div id="column-content"><div id="content">
	<a id="top"></a>
	
	<h1 id="firstHeading" class="firstHeading">Exercise:Vectorization</h1>
	<div id="bodyContent">
		<h3 id="siteSub">From Ufldl</h3>
		<div id="contentSub"></div>
		<div id="jump-to-nav">Jump to: <a href="#column-one">navigation</a>, <a href="#searchInput">search</a></div>
<table id="toc" class="toc"><tr><td><div id="toctitle"><h2>Contents</h2></div>
<ul>
<li class="toclevel-1 tocsection-1"><a href="#Vectorization"><span class="tocnumber">1</span> <span class="toctext">Vectorization</span></a>
<ul>
<li class="toclevel-2 tocsection-2"><a href="#Support_Code.2FData"><span class="tocnumber">1.1</span> <span class="toctext">Support Code/Data</span></a></li>
<li class="toclevel-2 tocsection-3"><a href="#Step_1:_Vectorize_your_Sparse_Autoencoder_Implementation"><span class="tocnumber">1.2</span> <span class="toctext">Step 1: Vectorize your Sparse Autoencoder Implementation</span></a></li>
<li class="toclevel-2 tocsection-4"><a href="#Step_2:_Learn_features_for_handwritten_digits"><span class="tocnumber">1.3</span> <span class="toctext">Step 2: Learn features for handwritten digits</span></a></li>
</ul>
</li>
</ul>
</td></tr></table><script>if (window.showTocToggle) { var tocShowText = "show"; var tocHideText = "hide"; showTocToggle(); } </script>
<h2> <span class="mw-headline" id="Vectorization"> Vectorization </span></h2>
<p>In the previous problem set, we implemented a sparse autoencoder for patches taken from natural images. In this problem set, you will vectorize your code to make it run much faster, and further adapt your sparse autoencoder to work on images of handwritten digits.  Your network for learning from handwritten digits will be much larger than the one you'd trained on the natural images, and so using the original implementation would have been painfully slow.  But with a vectorized implementation of the autoencoder, you will be able to get this to run in a reasonable amount of computation time. 
</p>
<h3> <span class="mw-headline" id="Support_Code.2FData"> Support Code/Data </span></h3>
<p>The following additional files are required for this exercise:
</p>
<ul><li> <a href="http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz" class="external text" rel="nofollow">MNIST Dataset (Training Images)</a>
</li><li> <a href="http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz" class="external text" rel="nofollow">MNIST Dataset (Training Labels)</a>
</li><li> <a href="/stanford-ufldl/archive/wiki/Using_the_MNIST_Dataset" title="Using the MNIST Dataset"> Support functions for loading MNIST in Matlab </a>
</li></ul>
<h3> <span class="mw-headline" id="Step_1:_Vectorize_your_Sparse_Autoencoder_Implementation"> Step 1: Vectorize your Sparse Autoencoder Implementation </span></h3>
<p>Using the ideas from <a href="/stanford-ufldl/archive/wiki/Vectorization" title="Vectorization">Vectorization</a> and <a href="/stanford-ufldl/archive/wiki/Neural_Network_Vectorization" title="Neural Network Vectorization">Neural Network Vectorization</a>, vectorize your implementation of <tt>sparseAutoencoderCost.m</tt>. In our implementation, we were able to remove all for-loops with the use of matrix operations and <tt>repmat</tt>. (If you want to play with more advanced vectorization ideas, also type <tt>help bsxfun</tt>.  The <tt>bsxfun</tt> function provides an alternative to <tt>repmat</tt> for some of the vectorization steps, but is not necessary for this exercise).  A vectorized version of our sparse autoencoder code ran in under one minute on a fast computer (for learning 25 features from 10000 8x8 image patches). 
</p><p>(Note that you do not need to vectorize the code in the other files.)
</p>
<h3> <span class="mw-headline" id="Step_2:_Learn_features_for_handwritten_digits"> Step 2: Learn features for handwritten digits </span></h3>
<p>Now that you have vectorized the code, it is easy to learn larger sets of features on medium sized images. In this part of the exercise, you will use your sparse autoencoder to learn features for handwritten digits from the MNIST dataset.  
</p><p>The MNIST data is available at <a href="http://yann.lecun.com/exdb/mnist/" class="external autonumber" rel="nofollow">[1]</a>. Download the file <tt>train-images-idx3-ubyte.gz</tt> and decompress it. After obtaining the source images, you should use <a href="/stanford-ufldl/archive/wiki/Using_the_MNIST_Dataset" title="Using the MNIST Dataset"> helper functions that we provide</a> to load the data into Matlab as matrices.  While the helper functions that we provide will load both the input examples <span class="texhtml"><i>x</i></span> and the class labels <span class="texhtml"><i>y</i></span>, for this assignment, you will only need the input examples <span class="texhtml"><i>x</i></span> since the sparse autoencoder is an <i>unsupervised</i> learning algorithm.  (In a later assignment, we will use the labels <span class="texhtml"><i>y</i></span> as well.) 
</p><p>The following set of parameters worked well for us to learn good features on the MNIST dataset:
</p>
<pre>visibleSize = 28*28
hiddenSize = 196
sparsityParam = 0.1
lambda = 3e-3
beta = 3
patches = first 10000 images from the MNIST dataset
</pre>
<p>After 400 iterations of updates using minFunc, your autoencoder should have learned features that resemble pen strokes.  In other words, this has learned to represent handwritten characters in terms of what pen strokes appear in an image.  Our implementation takes around 15-20 minutes on a fast machine. Visualized, the features should look like the following image: 
</p><p><a href="" class="image"><img alt="MnistVectorizationEx.png" src="/stanford-ufldl/archive/wiki/images/thumb/a/a3/MnistVectorizationEx.png/400px-MnistVectorizationEx.png" width="400" height="400"/></a>
</p><p>If your parameters are improperly tuned, or if your implementation of the autoencoder is buggy, you may get one of the following images instead:
</p>
<table>
<tr><td><a href="" class="image"><img alt="MNIST-false-bad-1.png" src="/stanford-ufldl/archive/wiki/images/6/63/MNIST-false-bad-1.png" width="240" height="244"/></a></td><td><a href="" class="image"><img alt="MNIST-false-bad-2.png" src="/stanford-ufldl/archive/wiki/images/e/eb/MNIST-false-bad-2.png" width="240" height="242"/></a></td></tr>
</table>
<p>If your image looks like one of the above images, check your code and parameters again. Learning these features are a prelude to the later exercises, where we shall see how they will be useful for classification.
</p><p><br/>
</p>
<div style="text-align: center;font-size:small;background-color: #eeeeee; border-style: solid; border-width: 1px; padding: 5px">
<p><a href="/stanford-ufldl/archive/wiki/Vectorization" title="Vectorization">Vectorization</a> | <a href="/stanford-ufldl/archive/wiki/Logistic_Regression_Vectorization_Example" title="Logistic Regression Vectorization Example">Logistic Regression Vectorization Example</a> | <a href="/stanford-ufldl/archive/wiki/Neural_Network_Vectorization" title="Neural Network Vectorization">Neural Network Vectorization</a> | <strong class="selflink">Exercise:Vectorization</strong>
</p>
</div>

<!-- 
NewPP limit report
Preprocessor node count: 29/1000000
Post-expand include size: 265/2097152 bytes
Template argument size: 0/2097152 bytes
Expensive parser function count: 0/100
-->

<div class="printfooter">
</div>		<div id="catlinks" class="catlinks catlinks-allhidden"></div>		<!-- end content -->
				<div class="visualClear"></div>
	</div>
</div></div>
<div id="column-one">
	<div id="p-cactions" class="portlet">
		<h5>Views</h5>
		<div class="pBody">
			<ul>
				 <li id="ca-nstab-main" class="selected"><a href="/stanford-ufldl/archive/wiki/Exercise_Vectorization" title="View the content page [c]" accesskey="c">Page</a></li>
				 <li id="ca-talk" class="new"><a href="" title="Discussion about the content page [t]" accesskey="t">Discussion</a></li>
				 <li id="ca-viewsource"><a href="" title="This page is protected.
You can view its source [e]" accesskey="e">View source</a></li>
				 <li id="ca-history"><a href="" title="Past revisions of this page [h]" accesskey="h">History</a></li>
			</ul>
		</div>
	</div>
	<div class="portlet" id="p-personal">
		<h5>Personal tools</h5>
		<div class="pBody">
			<ul>
			</ul>
		</div>
	</div>
	<div class="portlet" id="p-logo">
		<a style="background-image: url(/stanford-ufldl/archive/wiki/skins/common/images/dolphin-openclipart.png);" href="/stanford-ufldl/archive/wiki/Main_Page" title="Visit the main page"></a>
	</div>
	<script type="text/javascript"> if (window.isMSIE55) fixalpha(); </script>
	<div class="generated-sidebar portlet" id="p-ufldl_resources">
		<h5>ufldl resources</h5>
		<div class="pBody">
			<ul>
				<li id="n-UFLDL-Tutorial"><a href="/stanford-ufldl/archive/wiki/UFLDL_Tutorial">UFLDL Tutorial</a></li>
				<li id="n-Recommended-Readings"><a href="/stanford-ufldl/archive/wiki/UFLDL_Recommended_Readings">Recommended Readings</a></li>
			</ul>
		</div>
	</div>
	<div class="generated-sidebar portlet" id="p-wiki">
		<h5>wiki</h5>
		<div class="pBody">
			<ul>
				<li id="n-mainpage-description"><a href="/stanford-ufldl/archive/wiki/Main_Page" title="Visit the main page [z]" accesskey="z">Main page</a></li>
				<li id="n-recentchanges"><a href="" title="The list of recent changes in the wiki [r]" accesskey="r">Recent changes</a></li>
				<li id="n-randompage"><a href="" title="Load a random page [x]" accesskey="x">Random page</a></li>
				<li id="n-help"><a href="" title="The place to find out">Help</a></li>
			</ul>
		</div>
	</div>
	<div id="p-search" class="portlet">
		<h5><label for="searchInput">Search</label></h5>
		<div id="searchBody" class="pBody">
			<form action="" id="searchform">
				<input type="hidden" name="title" value="Special:Search" disabled/>
				<input id="searchInput" title="Search Ufldl" accesskey="f" type="search" name="search" disabled/>
				<input type="submit" name="go" class="searchButton" id="searchGoButton" value="Go" title="Go to a page with this exact name if exists" disabled/>&nbsp;
				<input type="submit" name="fulltext" class="searchButton" id="mw-searchButton" value="Search" title="Search the pages for this text" disabled/>
			</form>
		</div>
	</div>
	<div class="portlet" id="p-tb">
		<h5>Toolbox</h5>
		<div class="pBody">
			<ul>
				<li id="t-whatlinkshere"><a href="" title="List of all wiki pages that link here [j]" accesskey="j">What links here</a></li>
				<li id="t-recentchangeslinked"><a href="" title="Recent changes in pages linked from this page [k]" accesskey="k">Related changes</a></li>
<li id="t-specialpages"><a href="" title="List of all special pages [q]" accesskey="q">Special pages</a></li>
				<li id="t-print"><a href="" rel="alternate" title="Printable version of this page [p]" accesskey="p">Printable version</a></li>				<li id="t-permalink"><a href="" title="Permanent link to this revision of the page">Permanent link</a></li>			</ul>
		</div>
	</div>
</div><!-- end of the left (by default at least) column -->
<div class="visualClear"></div>
<div id="footer">
	<ul id="f-list">
		<li id="lastmod"> This page was last modified on 26 May 2011, at 11:00.</li>
		<li id="privacy"><a href="/stanford-ufldl/archive/wiki/Ufldl_Privacy_policy" title="Ufldl:Privacy policy">Privacy policy</a></li>
		<li id="about"><a href="/stanford-ufldl/archive/wiki/Ufldl_About" title="Ufldl:About">About Ufldl</a></li>
		<li id="disclaimer"><a href="/stanford-ufldl/archive/wiki/Ufldl_General_disclaimer" title="Ufldl:General disclaimer">Disclaimers</a></li>
	</ul>
</div>
</div>

<!-- Served in 0.122 secs. -->
</body>
</html>
