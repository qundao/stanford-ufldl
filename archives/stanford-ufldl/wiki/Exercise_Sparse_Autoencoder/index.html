
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Exercise:Sparse Autoencoder - Ufldl</title>
<link rel="stylesheet" href="/wayback-ufldl/stanford-ufldl/wiki/skins/common/shared.css" media="screen"/>
<link rel="stylesheet" href="/wayback-ufldl/stanford-ufldl/wiki/skins/monobook/main.css" media="screen"/>

</head>

<body class="mediawiki ltr ns-0 ns-subject page-Exercise_Sparse_Autoencoder skin-monobook">
<div id="globalWrapper">
<div id="column-content"><div id="content">
	<a id="top"></a>
	
	<h1 id="firstHeading" class="firstHeading">Exercise:Sparse Autoencoder</h1>
	<div id="bodyContent">
		<h3 id="siteSub">From Ufldl</h3>
		<div id="contentSub"></div>
		<div id="jump-to-nav">Jump to: <a href="#column-one">navigation</a>, <a href="#searchInput">search</a></div>
<table id="toc" class="toc"><tr><td><div id="toctitle"><h2>Contents</h2></div>
<ul>
<li class="toclevel-1 tocsection-1"><a href="#Download_Related_Reading"><span class="tocnumber">1</span> <span class="toctext">Download Related Reading</span></a></li>
<li class="toclevel-1 tocsection-2"><a href="#Sparse_autoencoder_implementation"><span class="tocnumber">2</span> <span class="toctext">Sparse autoencoder implementation</span></a>
<ul>
<li class="toclevel-2 tocsection-3"><a href="#Step_1:_Generate_training_set"><span class="tocnumber">2.1</span> <span class="toctext">Step 1: Generate training set</span></a></li>
<li class="toclevel-2 tocsection-4"><a href="#Step_2:_Sparse_autoencoder_objective"><span class="tocnumber">2.2</span> <span class="toctext">Step 2: Sparse autoencoder objective</span></a></li>
<li class="toclevel-2 tocsection-5"><a href="#Step_3:_Gradient_checking"><span class="tocnumber">2.3</span> <span class="toctext">Step 3: Gradient checking</span></a></li>
<li class="toclevel-2 tocsection-6"><a href="#Step_4:_Train_the_sparse_autoencoder"><span class="tocnumber">2.4</span> <span class="toctext">Step 4: Train the sparse autoencoder</span></a></li>
<li class="toclevel-2 tocsection-7"><a href="#Step_5:_Visualization"><span class="tocnumber">2.5</span> <span class="toctext">Step 5: Visualization</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-8"><a href="#Results"><span class="tocnumber">3</span> <span class="toctext">Results</span></a></li>
</ul>
</td></tr></table><script>if (window.showTocToggle) { var tocShowText = "show"; var tocHideText = "hide"; showTocToggle(); } </script>
<h2> <span class="mw-headline" id="Download_Related_Reading">Download Related Reading</span></h2>
<ul><li> <a href="http://nlp.stanford.edu/~socherr/sparseAutoencoder_2011new.pdf" class="external text" rel="nofollow">sparseae_reading.pdf</a>
</li><li> <a href="http://www.stanford.edu/class/cs294a/cs294a_2011-assignment.pdf" class="external text" rel="nofollow">sparseae_exercise.pdf</a>
</li></ul>
<h2> <span class="mw-headline" id="Sparse_autoencoder_implementation">Sparse autoencoder implementation</span></h2>
<p>In this problem set, you will implement the sparse autoencoder
algorithm, and show how it discovers that edges are a good
representation for natural images. (Images provided by
Bruno Olshausen.) The sparse autoencoder algorithm is described in
the lecture notes found on the course website.
</p><p>In the file <a href="http://ufldl.stanford.edu/wiki/resources/sparseae_exercise.zip" class="external text" rel="nofollow">sparseae_exercise.zip</a>, we have provided some starter code in
Matlab. You should write your code at the places indicated
in the files ("<tt>YOUR CODE HERE</tt>"). You have to complete the following files:
<tt>sampleIMAGES.m, sparseAutoencoderCost.m, computeNumericalGradient.m</tt>. 
The starter code in <tt>train.m</tt> shows how these functions are used.
</p><p>Specifically, in this exercise you will implement a sparse autoencoder, 
trained with 8&times;8 image patches using the L-BFGS optimization algorithm.
</p><p><b>A note on the software:</b> The provided .zip file includes a subdirectory
<tt>minFunc</tt> with 3rd party software implementing L-BFGS, that 
is licensed under a Creative Commons, Attribute, Non-Commercial license.  
If you need to use this software for commercial purposes, you can 
download and use a different function (fminlbfgs) that can serve the same
purpose, but runs ~3x slower for this exercise (and thus is less recommended). 
You can read more about this in the <a href="/wayback-ufldl/stanford-ufldl/wiki/Fminlbfgs_Details" title="Fminlbfgs Details">Fminlbfgs_Details</a> page. 
</p><p><br/>
</p>
<h3> <span class="mw-headline" id="Step_1:_Generate_training_set">Step 1: Generate training set</span></h3>
<p>The first step is to generate a training set.   To get a single training 
example <span class="texhtml"><i>x</i></span>, randomly pick one of the 10 images, then randomly sample 
an 8&times;8 image patch from the selected image, and convert the image patch (either 
in row-major order or column-major order; it doesn't matter) into a 64-dimensional 
vector to get a training example <img class="tex" alt="x \in \Re^{64}." src="/wayback-ufldl/stanford-ufldl/wiki/images/math/5/2/e/52e8298f9075e83d832c225274661c53.png"/>
</p><p>Complete the code in <tt>sampleIMAGES.m</tt>.  Your code should sample 10000 image 
patches and concatenate them into a 64&times;10000 matrix. 
</p><p>To make sure your implementation is working, run the code in "Step 1" of <tt>train.m</tt>.
This should result in a plot of a random sample of 200 patches from the dataset. 
</p><p><b>Implementational tip:</b> When we run our implemented <tt>
sampleImages()</tt>, it takes under 5 seconds.  If your implementation
takes over 30 seconds, it may be because you are accidentally making a
copy of an entire 512&times;512 image each time you're picking a random
image.  By copying a 512&times;512 image 10000 times, this can make your
implementation much less efficient.  While this doesn't slow down your
code significantly for this exercise (because we have only 10000
examples), when we scale to much larger problems later this quarter
with <span class="texhtml">10<sup>6</sup></span> or more examples, this will significantly slow down your
code.  Please implement <tt>sampleIMAGES</tt> so that you aren't making a
copy of an entire 512&times;512 image each time you need to cut out an 8x8
image patch.
</p>
<h3> <span class="mw-headline" id="Step_2:_Sparse_autoencoder_objective">Step 2: Sparse autoencoder objective</span></h3>
<p>Implement code to compute the sparse autoencoder cost function <span class="texhtml"><i>J</i><sub>sparse</sub>(<i>W</i>,<i>b</i>)</span> 
(Section 3 of the lecture notes)
and the corresponding derivatives of <span class="texhtml"><i>J</i><sub>sparse</sub></span> with respect to 
the different parameters.  Use the sigmoid function for the activation function, 
<img class="tex" alt="f(z) = \frac{1}{{1+e^{-z}}}" src="/wayback-ufldl/stanford-ufldl/wiki/images/math/4/a/e/4ae7d98ac96ae42135ae42929a235787.png"/>. 
In particular, complete the code in <tt>sparseAutoencoderCost.m</tt>.
</p><p>The sparse autoencoder is parameterized by matrices 
<img class="tex" alt="W^{(1)} \in \Re^{s_1\times s_2}" src="/wayback-ufldl/stanford-ufldl/wiki/images/math/1/2/1/12193f1859b9cafbf3bdcd4cfc62ecb7.png"/>,
<img class="tex" alt="W^{(2)} \in \Re^{s_2\times s_3}" src="/wayback-ufldl/stanford-ufldl/wiki/images/math/f/e/d/fedc3aec5abaabac539e73a60cd9465f.png"/> 
vectors 
<img class="tex" alt="b^{(1)} \in \Re^{s_2}" src="/wayback-ufldl/stanford-ufldl/wiki/images/math/9/9/d/99dba513cd3e3ea1d9e51ef34766a336.png"/>, 
<img class="tex" alt="b^{(2)} \in \Re^{s_3}" src="/wayback-ufldl/stanford-ufldl/wiki/images/math/e/1/8/e186d54c3d04fca48aca0a5c4ccd8bf0.png"/>.
However, for subsequent notational convenience, we will "unroll" all of these parameters
into a very long parameter vector <span class="texhtml">&theta;</span> with <span class="texhtml"><i>s</i><sub>1</sub><i>s</i><sub>2</sub> + <i>s</i><sub>2</sub><i>s</i><sub>3</sub> + <i>s</i><sub>2</sub> + <i>s</i><sub>3</sub></span> elements.  The
code for converting between the <span class="texhtml">(<i>W</i><sup>(1)</sup>,<i>W</i><sup>(2)</sup>,<i>b</i><sup>(1)</sup>,<i>b</i><sup>(2)</sup>)</span> and the <span class="texhtml">&theta;</span> parameterization 
is already provided in the starter code.
</p><p><b>Implementational tip:</b> The objective <span class="texhtml"><i>J</i><sub>sparse</sub>(<i>W</i>,<i>b</i>)</span> contains 3 terms, corresponding
to the squared error term, the weight decay term, and the sparsity penalty.  You're welcome
to implement this however you want, but for ease of debugging,
you might implement the cost function and derivative computation (backpropagation) only for the 
squared error term first (this corresponds to setting <span class="texhtml">&lambda; = &beta; = 0</span>), and implement 
the gradient checking method in the next section to first verify that this code is correct.  Then only
after you have verified that the objective and derivative calculations corresponding to the squared error 
term are working, add in code to compute the weight decay and sparsity penalty terms and their corresponding derivatives. 
</p>
<h3> <span class="mw-headline" id="Step_3:_Gradient_checking">Step 3: Gradient checking</span></h3>
<p>Following Section 2.3 of the lecture notes, implement code for gradient checking.  
Specifically, complete the code in <tt>computeNumericalGradient.m</tt>.  Please 
use <tt>EPSILON</tt> = 10<sup>-4</sup> as described in the lecture notes. 
</p><p>We've also provided code in <tt>checkNumericalGradient.m</tt> for you to test your code. 
This code defines a simple quadratic function <img class="tex" alt="h: \Re^2 \mapsto \Re" src="/wayback-ufldl/stanford-ufldl/wiki/images/math/f/2/b/f2b7676d71d07e5769e6e8e58d6469f2.png"/> given by 
<img class="tex" alt="h(x) = x_1^2 + 3x_1 x_2" src="/wayback-ufldl/stanford-ufldl/wiki/images/math/5/d/b/5db1a6e3a00429921bdd48a41dfea2f3.png"/>, and evaluates it at the point <span class="texhtml"><i>x</i> = (4,10)<sup><i>T</i></sup></span>.  It allows you
to verify that your numerically evaluated gradient is very close to the true (analytically
computed) gradient.  
</p><p>After using <tt>checkNumericalGradient.m</tt> to make sure your implementation is correct, 
next use <tt>computeNumericalGradient.m</tt> to make sure that your <tt>sparseAutoencoderCost.m</tt>
is computing derivatives correctly.  For details, see Steps 3 in <tt>train.m</tt>.  We strongly
encourage you not to proceed to the next step until you've verified that your derivative
computations are correct. 
</p><p><b>Implementational tip:</b> If you are debugging your code, performing gradient checking on smaller models 
and smaller training sets (e.g., using only 10 training examples and 1-2 hidden 
units) may speed things up.
</p>
<h3> <span class="mw-headline" id="Step_4:_Train_the_sparse_autoencoder">Step 4: Train the sparse autoencoder</span></h3>
<p>Now that you have code that computes 
<span class="texhtml"><i>J</i><sub>sparse</sub></span> and its derivatives, we're ready to minimize 
<span class="texhtml"><i>J</i><sub>sparse</sub></span> with respect to its parameters, and thereby train our
sparse autoencoder.
</p><p>We will use the L-BFGS algorithm.  This is provided to you in a function called
<tt>minFunc</tt> (code provided by Mark Schmidt) included in the starter code.  (For the purpose of this
assignment, you only need to call minFunc with the default parameters. You do
not need to know how L-BFGS works.)  We have already provided code in <tt>train.m</tt>
(Step 4) to call <tt>minFunc</tt>.  The <tt>minFunc</tt> code assumes that the parameters
to be optimized are a long parameter vector; so we will use the "<span class="texhtml">&theta;</span>" parameterization
rather than the "<span class="texhtml">(<i>W</i><sup>(1)</sup>,<i>W</i><sup>(2)</sup>,<i>b</i><sup>(1)</sup>,<i>b</i><sup>(2)</sup>)</span>" parameterization when passing our parameters
to it.
</p><p>Train a sparse autoencoder with 64 input units, 25 hidden units, and 64 output units.
In our starter code, we have provided a function for initializing the parameters.
We initialize the biases <img class="tex" alt="b^{(l)}_i" src="/wayback-ufldl/stanford-ufldl/wiki/images/math/6/e/a/6ea0ff7533b239d7ad97668ee35c259d.png"/> to zero, and the weights <img class="tex" alt="W^{(l)}_{ij}" src="/wayback-ufldl/stanford-ufldl/wiki/images/math/9/1/8/9183f327132cdf5ca9876aa4038f6e2f.png"/>
to random numbers drawn uniformly from the interval 
<img class="tex" alt="\left[-\sqrt{\frac{6}{n_{\rm in}+n_{\rm out}+1}},\sqrt{\frac{6}{n_{\rm in}+n_{\rm out}+1}}\,\right]" src="/wayback-ufldl/stanford-ufldl/wiki/images/math/b/1/e/b1e650d9fdd8c53c515c23d49fc8fe40.png"/>, where <span class="texhtml"><i>n</i><sub>in</sub></span> is the fan-in
(the number of inputs feeding into a node) and <span class="texhtml"><i>n</i><sub>out</sub></span> is the fan-in (the number of
units that a node feeds into).
</p><p>The values we provided for the various parameters (<span class="texhtml">&lambda;,&beta;,&rho;</span>, etc.)
should work, but feel free to play with different settings of the parameters as
well.
</p><p><b>Implementational tip:</b> Once you have your backpropagation implementation correctly computing the derivatives (as verified using gradient checking in Step 3), when you are now using it with L-BFGS to optimize <span class="texhtml"><i>J</i><sub>sparse</sub>(<i>W</i>,<i>b</i>)</span>, make sure you're not doing gradient-checking on every step.  Backpropagation can be used to compute the derivatives of <span class="texhtml"><i>J</i><sub>sparse</sub>(<i>W</i>,<i>b</i>)</span> fairly efficiently, and if you were additionally computing the gradient numerically on every step, this would slow down your program significantly. 
</p><p><br/>
</p>
<h3> <span class="mw-headline" id="Step_5:_Visualization">Step 5: Visualization</span></h3>
<p>After training the autoencoder, use <tt>display_network.m</tt> to visualize the learned
weights.  (See <tt>train.m</tt>, Step 5.)  Run "<tt>print -djpeg weights.jpg</tt>" to save
the visualization to a file "<tt>weights.jpg</tt>" (which you will submit together with
your code). 
</p>
<h2> <span class="mw-headline" id="Results">Results</span></h2>
<p>To successfully complete this assignment, you should demonstrate your sparse
autoencoder algorithm learning a set of edge detectors.  For example, this
was the visualization we obtained: 
</p><p><br/>
<a href="" class="image"><img alt="Gabor.jpg" src="/wayback-ufldl/stanford-ufldl/wiki/images/0/0f/Gabor.jpg" width="380" height="380"/></a>
</p><p><br/>
Our implementation took around 5 minutes to run on a fast computer.
In case you end up needing to try out multiple implementations or 
different parameter values, be sure to budget enough time for debugging 
and to run the experiments you'll need. 
</p><p>Also, by way of comparison, here are some visualizations from implementations
that we do not consider successful (either a buggy implementation, or where
the parameters were poorly tuned):
</p><p><br/>
<a href="" class="image"><img alt="Badfilter1.jpg" src="/wayback-ufldl/stanford-ufldl/wiki/images/thumb/a/ad/Badfilter1.jpg/240px-Badfilter1.jpg" width="240" height="239"/></a> <a href="" class="image"><img alt="Badfilter2.jpg" src="/wayback-ufldl/stanford-ufldl/wiki/images/thumb/1/11/Badfilter2.jpg/240px-Badfilter2.jpg" width="240" height="239"/></a> <a href="" class="image"><img alt="Badfilter3.jpg" src="/wayback-ufldl/stanford-ufldl/wiki/images/thumb/f/fb/Badfilter3.jpg/240px-Badfilter3.jpg" width="240" height="237"/></a>
</p><p><a href="" class="image"><img alt="Badfilter4.jpg" src="/wayback-ufldl/stanford-ufldl/wiki/images/thumb/3/32/Badfilter4.jpg/240px-Badfilter4.jpg" width="240" height="238"/></a> <a href="" class="image"><img alt="Badfilter5.jpg" src="/wayback-ufldl/stanford-ufldl/wiki/images/thumb/6/61/Badfilter5.jpg/240px-Badfilter5.jpg" width="240" height="238"/></a> <a href="" class="image"><img alt="Badfilter6.jpg" src="/wayback-ufldl/stanford-ufldl/wiki/images/thumb/9/91/Badfilter6.jpg/240px-Badfilter6.jpg" width="240" height="238"/></a>
</p><p><br/>
</p>
<div style="text-align: center;font-size:small;background-color: #eeeeee; border-style: solid; border-width: 1px; padding: 5px">
<p><a href="/wayback-ufldl/stanford-ufldl/wiki/Neural_Networks" title="Neural Networks">Neural Networks</a> | <a href="/wayback-ufldl/stanford-ufldl/wiki/Backpropagation_Algorithm" title="Backpropagation Algorithm">Backpropagation Algorithm</a> | <a href="/wayback-ufldl/stanford-ufldl/wiki/Gradient_checking_and_advanced_optimization" title="Gradient checking and advanced optimization">Gradient checking and advanced optimization</a> | <a href="/wayback-ufldl/stanford-ufldl/wiki/Autoencoders_and_Sparsity" title="Autoencoders and Sparsity">Autoencoders and Sparsity</a> | <a href="/wayback-ufldl/stanford-ufldl/wiki/Visualizing_a_Trained_Autoencoder" title="Visualizing a Trained Autoencoder">Visualizing a Trained Autoencoder</a> | <a href="/wayback-ufldl/stanford-ufldl/wiki/Sparse_Autoencoder_Notation_Summary" title="Sparse Autoencoder Notation Summary">Sparse Autoencoder Notation Summary</a> | <strong class="selflink">Exercise:Sparse Autoencoder</strong>
</p>
</div>

<!-- 
NewPP limit report
Preprocessor node count: 312/1000000
Post-expand include size: 385/2097152 bytes
Template argument size: 0/2097152 bytes
Expensive parser function count: 0/100
-->

<div class="printfooter">
</div>		<div id="catlinks" class="catlinks"><div id="mw-normal-catlinks"><a href="" title="Special:Categories">Category</a>: <span dir="ltr"><a href="" class="new" title="Category:Exercises (page does not exist)">Exercises</a></span></div></div>		<!-- end content -->
				<div class="visualClear"></div>
	</div>
</div></div>
<div id="column-one">
	<div id="p-cactions" class="portlet">
		<h5>Views</h5>
		<div class="pBody">
			<ul>
				 <li id="ca-nstab-main" class="selected"><a href="/wayback-ufldl/stanford-ufldl/wiki/Exercise_Sparse_Autoencoder" title="View the content page [c]" accesskey="c">Page</a></li>
				 <li id="ca-talk" class="new"><a href="" title="Discussion about the content page [t]" accesskey="t">Discussion</a></li>
				 <li id="ca-viewsource"><a href="" title="This page is protected.
You can view its source [e]" accesskey="e">View source</a></li>
				 <li id="ca-history"><a href="" title="Past revisions of this page [h]" accesskey="h">History</a></li>
			</ul>
		</div>
	</div>
	<div class="portlet" id="p-personal">
		<h5>Personal tools</h5>
		<div class="pBody">
			<ul>
			</ul>
		</div>
	</div>
	<div class="portlet" id="p-logo">
		<a style="background-image: url(/wayback-ufldl/stanford-ufldl/wiki/skins/common/images/dolphin-openclipart.png);" href="/wayback-ufldl/stanford-ufldl/wiki/Main_Page" title="Visit the main page"></a>
	</div>
	<script type="text/javascript"> if (window.isMSIE55) fixalpha(); </script>
	<div class="generated-sidebar portlet" id="p-ufldl_resources">
		<h5>ufldl resources</h5>
		<div class="pBody">
			<ul>
				<li id="n-UFLDL-Tutorial"><a href="/wayback-ufldl/stanford-ufldl/wiki/UFLDL_Tutorial">UFLDL Tutorial</a></li>
				<li id="n-Recommended-Readings"><a href="/wayback-ufldl/stanford-ufldl/wiki/UFLDL_Recommended_Readings">Recommended Readings</a></li>
			</ul>
		</div>
	</div>
	<div class="generated-sidebar portlet" id="p-wiki">
		<h5>wiki</h5>
		<div class="pBody">
			<ul>
				<li id="n-mainpage-description"><a href="/wayback-ufldl/stanford-ufldl/wiki/Main_Page" title="Visit the main page [z]" accesskey="z">Main page</a></li>
				<li id="n-recentchanges"><a href="" title="The list of recent changes in the wiki [r]" accesskey="r">Recent changes</a></li>
				<li id="n-randompage"><a href="" title="Load a random page [x]" accesskey="x">Random page</a></li>
				<li id="n-help"><a href="" title="The place to find out">Help</a></li>
			</ul>
		</div>
	</div>
	<div id="p-search" class="portlet">
		<h5><label for="searchInput">Search</label></h5>
		<div id="searchBody" class="pBody">
			<form action="" id="searchform">
				<input type="hidden" name="title" value="Special:Search" disabled/>
				<input id="searchInput" title="Search Ufldl" accesskey="f" type="search" name="search" disabled/>
				<input type="submit" name="go" class="searchButton" id="searchGoButton" value="Go" title="Go to a page with this exact name if exists" disabled/>&nbsp;
				<input type="submit" name="fulltext" class="searchButton" id="mw-searchButton" value="Search" title="Search the pages for this text" disabled/>
			</form>
		</div>
	</div>
	<div class="portlet" id="p-tb">
		<h5>Toolbox</h5>
		<div class="pBody">
			<ul>
				<li id="t-whatlinkshere"><a href="" title="List of all wiki pages that link here [j]" accesskey="j">What links here</a></li>
				<li id="t-recentchangeslinked"><a href="" title="Recent changes in pages linked from this page [k]" accesskey="k">Related changes</a></li>
<li id="t-specialpages"><a href="" title="List of all special pages [q]" accesskey="q">Special pages</a></li>
				<li id="t-print"><a href="" rel="alternate" title="Printable version of this page [p]" accesskey="p">Printable version</a></li>				<li id="t-permalink"><a href="" title="Permanent link to this revision of the page">Permanent link</a></li>			</ul>
		</div>
	</div>
</div><!-- end of the left (by default at least) column -->
<div class="visualClear"></div>
<div id="footer">
	<ul id="f-list">
		<li id="lastmod"> This page was last modified on 10 July 2012, at 14:34.</li>
		<li id="privacy"><a href="/wayback-ufldl/stanford-ufldl/wiki/Ufldl_Privacy_policy" title="Ufldl:Privacy policy">Privacy policy</a></li>
		<li id="about"><a href="/wayback-ufldl/stanford-ufldl/wiki/Ufldl_About" title="Ufldl:About">About Ufldl</a></li>
		<li id="disclaimer"><a href="/wayback-ufldl/stanford-ufldl/wiki/Ufldl_General_disclaimer" title="Ufldl:General disclaimer">Disclaimers</a></li>
	</ul>
</div>
</div>

<!-- Served in 0.111 secs. -->
</body>
</html>
