
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Data Preprocessing - Ufldl</title>
<link rel="stylesheet" href="/wayback-ufldl/stanford-ufldl/wiki/skins/common/shared.css" media="screen"/>
<link rel="stylesheet" href="/wayback-ufldl/stanford-ufldl/wiki/skins/monobook/main.css" media="screen"/>

</head>

<body class="mediawiki ltr ns-0 ns-subject page-Data_Preprocessing skin-monobook">
<div id="globalWrapper">
<div id="column-content"><div id="content">
	<a id="top"></a>
	
	<h1 id="firstHeading" class="firstHeading">Data Preprocessing</h1>
	<div id="bodyContent">
		<h3 id="siteSub">From Ufldl</h3>
		<div id="contentSub"></div>
		<div id="jump-to-nav">Jump to: <a href="#column-one">navigation</a>, <a href="#searchInput">search</a></div>
<table id="toc" class="toc"><tr><td><div id="toctitle"><h2>Contents</h2></div>
<ul>
<li class="toclevel-1 tocsection-1"><a href="#Overview"><span class="tocnumber">1</span> <span class="toctext">Overview</span></a></li>
<li class="toclevel-1 tocsection-2"><a href="#Data_Normalization"><span class="tocnumber">2</span> <span class="toctext">Data Normalization</span></a>
<ul>
<li class="toclevel-2 tocsection-3"><a href="#Simple_Rescaling"><span class="tocnumber">2.1</span> <span class="toctext">Simple Rescaling</span></a></li>
<li class="toclevel-2 tocsection-4"><a href="#Per-example_mean_subtraction"><span class="tocnumber">2.2</span> <span class="toctext">Per-example mean subtraction</span></a></li>
<li class="toclevel-2 tocsection-5"><a href="#Feature_Standardization"><span class="tocnumber">2.3</span> <span class="toctext">Feature Standardization</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-6"><a href="#PCA.2FZCA_Whitening"><span class="tocnumber">3</span> <span class="toctext">PCA/ZCA Whitening</span></a>
<ul>
<li class="toclevel-2 tocsection-7"><a href="#Reconstruction_Based_Models"><span class="tocnumber">3.1</span> <span class="toctext">Reconstruction Based Models</span></a></li>
<li class="toclevel-2 tocsection-8"><a href="#ICA-based_Models_.28with_orthogonalization.29"><span class="tocnumber">3.2</span> <span class="toctext">ICA-based Models (with orthogonalization)</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-9"><a href="#Large_Images"><span class="tocnumber">4</span> <span class="toctext">Large Images</span></a></li>
<li class="toclevel-1 tocsection-10"><a href="#Standard_Pipelines"><span class="tocnumber">5</span> <span class="toctext">Standard Pipelines</span></a>
<ul>
<li class="toclevel-2 tocsection-11"><a href="#Natural_Grey-scale_Images"><span class="tocnumber">5.1</span> <span class="toctext">Natural Grey-scale Images</span></a></li>
<li class="toclevel-2 tocsection-12"><a href="#Color_Images"><span class="tocnumber">5.2</span> <span class="toctext">Color Images</span></a></li>
<li class="toclevel-2 tocsection-13"><a href="#Audio_.28MFCC.2FSpectrograms.29"><span class="tocnumber">5.3</span> <span class="toctext">Audio (MFCC/Spectrograms)</span></a></li>
<li class="toclevel-2 tocsection-14"><a href="#MNIST_Handwritten_Digits"><span class="tocnumber">5.4</span> <span class="toctext">MNIST Handwritten Digits</span></a></li>
</ul>
</li>
</ul>
</td></tr></table><script>if (window.showTocToggle) { var tocShowText = "show"; var tocHideText = "hide"; showTocToggle(); } </script>
<h2> <span class="mw-headline" id="Overview"> Overview </span></h2>
<p>Data preprocessing plays a very important in many deep learning algorithms. In practice, many methods work best after the data has been normalized and whitened. However, the exact parameters for data preprocessing are usually not immediately apparent unless one has much experience working with the algorithms. In this page, we hope to demystify some of the preprocessing methods and also provide tips (and a "standard pipeline") for preprocessing data.
</p>
<div style="background-color: #eeeeee; border-style: dotted; padding: 5px">
<p>Tip: When approaching a dataset, the first thing to do is to look at the data itself and observe its properties. While the techniques here apply generally, you might want to opt to do certain things differently given your dataset. For example, one standard preprocessing trick is to subtract the mean of each data point from itself (also known as remove DC, local mean subtraction, subtractive normalization). While this makes sense for data such as natural images, it is less obvious for data where stationarity does not hold. 
</p>
</div>
<p><br/>
</p>
<h2> <span class="mw-headline" id="Data_Normalization"> Data Normalization </span></h2>
<p>A standard first step to data preprocessing is data normalization. While there are a few possible approaches, this step is usually clear depending on the data. The common methods for feature normalization are:
</p>
<ul><li> Simple Rescaling
</li><li> Per-example mean subtraction (a.k.a. remove DC)
</li><li> Feature Standardization (zero-mean and unit variance for each feature across the dataset)
</li></ul>
<p><br/>
</p>
<h3> <span class="mw-headline" id="Simple_Rescaling"> Simple Rescaling </span></h3>
<p>In simple rescaling, our goal is to rescale the data along each data dimension (possibly independently) so that the final data vectors lie in the range <span class="texhtml">[0,1]</span> or  <span class="texhtml">[ &minus; 1,1]</span>  (depending on your dataset). This is useful for later processing as many <i>default</i> parameters (e.g., epsilon in PCA-whitening) treat the data as if it has been scaled to a reasonable range. 
</p><p><b>Example: </b> When processing natural images, we often obtain pixel values in the range <span class="texhtml">[0,255]</span>. It is a common operation to rescale these values to  <span class="texhtml">[0,1]</span> by dividing the data by 255.
</p>
<h3> <span class="mw-headline" id="Per-example_mean_subtraction"> Per-example mean subtraction </span></h3>
<p>If your data is <i>stationary</i> (i.e., the statistics for each data dimension follow the same distribution), then you might want to consider subtracting the mean-value for each example (computed per-example). 
</p><p><b>Example:</b> In images, this normalization has the property of removing the average brightness (intensity) of the data point. In many cases, we are not interested in the illumination conditions of the image, but more so in the content; removing the average pixel value per data point makes sense here. <b>Note:</b> While this method is generally used for images, one might want to take more care when applying this to color images. In particular, the stationarity property does not generally apply across pixels in different color channels.
</p>
<h3> <span class="mw-headline" id="Feature_Standardization"> Feature Standardization </span></h3>
<p>Feature standardization refers to (independently) setting each dimension of the data to have zero-mean and unit-variance. This is the most common method for normalization and is generally used widely (e.g., when working with SVMs, feature standardization is often recommended as a preprocessing step). In practice, one achieves this by first computing the mean of each dimension (across the dataset) and subtracts this from each dimension. Next, each dimension is divided by its standard deviation. 
</p><p><b>Example: </b> When working with audio data, it is common to use <a href="http://en.wikipedia.org/wiki/Mel-frequency_cepstrum" class="external text" rel="nofollow">MFCCs</a> as the data representation. However, the first component (representing the DC) of the MFCC features often overshadow the other components. Thus, one method to restore balance to the components is to standardize the values in each component independently.
</p><p><br/>
</p>
<h2> <span class="mw-headline" id="PCA.2FZCA_Whitening"> PCA/ZCA Whitening </span></h2>
<p>After doing the simple normalizations, whitening is often the next preprocessing step employed that helps make our algorithms work better. In practice, many deep learning algorithms rely on whitening to learn good features.
</p><p>In performing PCA/ZCA whitening, it is pertinent to first zero-mean the features (across the dataset) to ensure that <img class="tex" alt=" \frac{1}{m} \sum_i x^{(i)} = 0 " src="/wayback-ufldl/stanford-ufldl/wiki/images/math/e/3/8/e38353138423fe3c99226921e02ee649.png"/>. Specifically, this should be done before computing the covariance matrix. (The only exception is when per-example mean subtraction is performed and the data is stationary across dimensions/pixels.)
</p><p>Next, one needs to select the value of <tt>epsilon</tt> to use when performing <a href="/wayback-ufldl/stanford-ufldl/wiki/Whitening" title="Whitening"> PCA/ZCA whitening</a> (recall that this was the regularization term that has an effect of <i>low-pass filtering</i> the data). It turns out that selecting this value can also play an important role for feature learning, we discuss two cases for selecting <tt>epsilon</tt>:
</p>
<h3> <span class="mw-headline" id="Reconstruction_Based_Models"> Reconstruction Based Models </span></h3>
<p>In models based on reconstruction (including Autoencoders, Sparse Coding, RBMs, k-Means), it is often preferable to set <tt>epsilon</tt> to a value such that low-pass filtering is achieved. One way to check this is to set a value for <tt>epsilon</tt>, run ZCA whitening, and thereafter visualize the data before and after whitening. If the value of epsilon is set too low, the data will look very noisy; conversely, if <tt>epsilon</tt> is set too high, you will see a "blurred" version of the original data. A good way to get a feel for the magnitude of <tt>epsilon</tt> to try is to plot the eigenvalues on a graph. As visible in the example graph below, you may get a "long tail" corresponding to the high frequency noise components. You will want to choose <tt>epsilon</tt> such that most of the "long tail" is filtered out, i.e. choose <tt>epsilon</tt> such that it is greater than most of the small eigenvalues corresponding to the noise.
</p><p><a href="" class="image"><img alt="ZCA Eigenvalues Plot.png" src="/wayback-ufldl/stanford-ufldl/wiki/images/9/91/ZCA_Eigenvalues_Plot.png" width="482" height="392"/></a>
</p><p>In reconstruction based models, the loss function includes a term that penalizes reconstructions that are far from the original inputs. Then, if <tt>epsilon</tt> is set too <i>low</i>, the data will contain a lot of noise which the model will need to reconstruct well. As a result, it is very important for reconstruction based models to have data that has been low-pass filtered.
</p>
<div style="background-color: #eeeeee; border-style: dotted; padding: 5px">
<p>Tip: If your data has been scaled reasonably (e.g., to <span class="texhtml">[0,1]</span>), start with <span class="texhtml"><i>e</i><i>p</i><i>s</i><i>i</i><i>l</i><i>o</i><i>n</i> = 0.01</span> or <span class="texhtml"><i>e</i><i>p</i><i>s</i><i>i</i><i>l</i><i>o</i><i>n</i> = 0.1</span>.
</p>
</div>
<h3> <span class="mw-headline" id="ICA-based_Models_.28with_orthogonalization.29"> ICA-based Models (with orthogonalization) </span></h3>
<p>For ICA-based models with orthogonalization, it is <i>very</i> important for the data to be as close to white (identity covariance) as possible. This is a side-effect of using orthogonalization to decorrelate the features learned (more details in <a href="/wayback-ufldl/stanford-ufldl/wiki/Independent_Component_Analysis" title="Independent Component Analysis"> ICA</a>). Hence, in this case, you will want to use an <tt>epsilon</tt> that is as small as possible (e.g., <span class="texhtml"><i>e</i><i>p</i><i>s</i><i>i</i><i>l</i><i>o</i><i>n</i> = 1<i>e</i> &minus; 6</span>).
</p><p><br/>
</p>
<div style="background-color: #eeeeee; border-style: dotted; padding: 5px">
<p>Tip: In PCA whitening, one also has the option of performing dimension reduction while whitening the data. This is usually an excellent idea since it can greatly speed up the algorithms (less computation and less parameters). A simple rule of thumb to choose how many principle components to retain is to keep enough components to have 99% of the variance retained (more details at <a href="/wayback-ufldl/stanford-ufldl/wiki/PCA#Number_of_components_to_retain" title="PCA"> PCA</a>)
</p>
</div>
<p><br/>
</p>
<div style="background-color: #eeeeee; border-style: dotted; padding: 5px">
<p>Note: When working in a classification framework, one should compute the PCA/ZCA whitening matrices based only on the training set. The following parameters used be saved for use with the test set: (a) average vector that was used to zero-mean the data, (b) whitening matrices. The test set should undergo the same preprocessing steps using these saved values.  
</p>
</div>
<h2> <span class="mw-headline" id="Large_Images"> Large Images </span></h2>
<p>For large images, PCA/ZCA based whitening methods are impractical as the covariance matrix is too large. For these cases, we defer to 1/f-whitening methods. (more details to come)
</p><p><br/>
</p>
<h2> <span class="mw-headline" id="Standard_Pipelines"> Standard Pipelines </span></h2>
<p>In this section, we describe several "standard pipelines" that have worked well for some datasets:
</p>
<h3> <span class="mw-headline" id="Natural_Grey-scale_Images"> Natural Grey-scale Images </span></h3>
<p>Since grey-scale images have the stationarity property, we usually first remove the mean-component from each data example separately (remove DC). After this step, PCA/ZCA whitening is often employed with a value of <tt>epsilon</tt> set large enough to low-pass filter the data.
</p>
<h3> <span class="mw-headline" id="Color_Images"> Color Images </span></h3>
<p>For color images, the stationarity property does not hold across color channels. Hence, we usually start by rescaling the data (making sure it is in <span class="texhtml">[0,1]</span>) ad then applying PCA/ZCA with a sufficiently large <tt>epsilon</tt>. Note that it is important to perform feature mean-normalization before computing the PCA transformation.
</p>
<h3> <span class="mw-headline" id="Audio_.28MFCC.2FSpectrograms.29"> Audio (MFCC/Spectrograms) </span></h3>
<p>For audio data (MFCC and Spectrograms), each dimension usually have different scales (variances); the first component of MFCCs, for example, is the DC component and usually has a larger magnitude than the other components. This is especially so when one includes the temporal derivatives (a common practice in audio processing). As a result, the preprocessing usually starts with simple data standardization (zero-mean, unit-variance per data dimension), followed by PCA/ZCA whitening (with an appropriate <tt>epsilon</tt>).
</p>
<h3> <span class="mw-headline" id="MNIST_Handwritten_Digits"> MNIST Handwritten Digits </span></h3>
<p>The MNIST dataset has pixel values in the range <span class="texhtml">[0,255]</span>. We thus start with simple rescaling to shift the data into the range <span class="texhtml">[0,1]</span>. In practice, removing the mean-value per example can also help feature learning. <i>Note: While one could also elect to use PCA/ZCA whitening on MNIST if desired, this is not often done in practice.</i>
</p><p><br/>
</p>
<div style="text-align: left;font-size:small;background-color: #eeeeee; border-style: solid; border-width: 1px; padding: 5px">
<p>Language&nbsp;: <a href="/wayback-ufldl/stanford-ufldl/wiki/%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86" title="数据预处理">中文</a>
</p>
</div>

<!-- 
NewPP limit report
Preprocessor node count: 179/1000000
Post-expand include size: 2021/2097152 bytes
Template argument size: 1539/2097152 bytes
Expensive parser function count: 0/100
-->

<div class="printfooter">
</div>		<div id="catlinks" class="catlinks catlinks-allhidden"></div>		<!-- end content -->
				<div class="visualClear"></div>
	</div>
</div></div>
<div id="column-one">
	<div id="p-cactions" class="portlet">
		<h5>Views</h5>
		<div class="pBody">
			<ul>
				 <li id="ca-nstab-main" class="selected"><a href="/wayback-ufldl/stanford-ufldl/wiki/Data_Preprocessing" title="View the content page [c]" accesskey="c">Page</a></li>
				 <li id="ca-talk" class="new"><a href="" title="Discussion about the content page [t]" accesskey="t">Discussion</a></li>
				 <li id="ca-viewsource"><a href="" title="This page is protected.
You can view its source [e]" accesskey="e">View source</a></li>
				 <li id="ca-history"><a href="" title="Past revisions of this page [h]" accesskey="h">History</a></li>
			</ul>
		</div>
	</div>
	<div class="portlet" id="p-personal">
		<h5>Personal tools</h5>
		<div class="pBody">
			<ul>
			</ul>
		</div>
	</div>
	<div class="portlet" id="p-logo">
		<a style="background-image: url(/wayback-ufldl/stanford-ufldl/wiki/skins/common/images/dolphin-openclipart.png);" href="/wayback-ufldl/stanford-ufldl/wiki/Main_Page" title="Visit the main page"></a>
	</div>
	<script type="text/javascript"> if (window.isMSIE55) fixalpha(); </script>
	<div class="generated-sidebar portlet" id="p-ufldl_resources">
		<h5>ufldl resources</h5>
		<div class="pBody">
			<ul>
				<li id="n-UFLDL-Tutorial"><a href="/wayback-ufldl/stanford-ufldl/wiki/UFLDL_Tutorial">UFLDL Tutorial</a></li>
				<li id="n-Recommended-Readings"><a href="/wayback-ufldl/stanford-ufldl/wiki/UFLDL_Recommended_Readings">Recommended Readings</a></li>
			</ul>
		</div>
	</div>
	<div class="generated-sidebar portlet" id="p-wiki">
		<h5>wiki</h5>
		<div class="pBody">
			<ul>
				<li id="n-mainpage-description"><a href="/wayback-ufldl/stanford-ufldl/wiki/Main_Page" title="Visit the main page [z]" accesskey="z">Main page</a></li>
				<li id="n-recentchanges"><a href="" title="The list of recent changes in the wiki [r]" accesskey="r">Recent changes</a></li>
				<li id="n-randompage"><a href="" title="Load a random page [x]" accesskey="x">Random page</a></li>
				<li id="n-help"><a href="" title="The place to find out">Help</a></li>
			</ul>
		</div>
	</div>
	<div id="p-search" class="portlet">
		<h5><label for="searchInput">Search</label></h5>
		<div id="searchBody" class="pBody">
			<form action="" id="searchform">
				<input type="hidden" name="title" value="Special:Search" disabled/>
				<input id="searchInput" title="Search Ufldl" accesskey="f" type="search" name="search" disabled/>
				<input type="submit" name="go" class="searchButton" id="searchGoButton" value="Go" title="Go to a page with this exact name if exists" disabled/>&nbsp;
				<input type="submit" name="fulltext" class="searchButton" id="mw-searchButton" value="Search" title="Search the pages for this text" disabled/>
			</form>
		</div>
	</div>
	<div class="portlet" id="p-tb">
		<h5>Toolbox</h5>
		<div class="pBody">
			<ul>
				<li id="t-whatlinkshere"><a href="" title="List of all wiki pages that link here [j]" accesskey="j">What links here</a></li>
				<li id="t-recentchangeslinked"><a href="" title="Recent changes in pages linked from this page [k]" accesskey="k">Related changes</a></li>
<li id="t-specialpages"><a href="" title="List of all special pages [q]" accesskey="q">Special pages</a></li>
				<li id="t-print"><a href="" rel="alternate" title="Printable version of this page [p]" accesskey="p">Printable version</a></li>				<li id="t-permalink"><a href="" title="Permanent link to this revision of the page">Permanent link</a></li>			</ul>
		</div>
	</div>
</div><!-- end of the left (by default at least) column -->
<div class="visualClear"></div>
<div id="footer">
	<ul id="f-list">
		<li id="lastmod"> This page was last modified on 8 April 2013, at 04:22.</li>
		<li id="privacy"><a href="/wayback-ufldl/stanford-ufldl/wiki/Ufldl_Privacy_policy" title="Ufldl:Privacy policy">Privacy policy</a></li>
		<li id="about"><a href="/wayback-ufldl/stanford-ufldl/wiki/Ufldl_About" title="Ufldl:About">About Ufldl</a></li>
		<li id="disclaimer"><a href="/wayback-ufldl/stanford-ufldl/wiki/Ufldl_General_disclaimer" title="Ufldl:General disclaimer">Disclaimers</a></li>
	</ul>
</div>
</div>

<!-- Served in 0.147 secs. -->
</body>
</html>
