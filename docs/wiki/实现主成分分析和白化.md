实现主成分分析和白化
==========

<!-- Jump to: [navigation](#column-one), [search](#searchInput) -->
在这一节里，我们将总结PCA, PCA白化和ZCA白化算法，并描述如何使用高效的线性代数库来实现它们。

首先，我们需要确保数据的均值（近似）为零。对于自然图像，我们通过减去每个图像块(patch)的均值（近似地）来达到这一目标。为此，我们计算每个图像块的均值，并从每个图像块中减去它的均值。（译注：参见PCA一章中“对图像数据应用PCA算法”一节）。Matlab实现如下：

```
avg = mean(x, 1);     % 分别为每个图像块计算像素强度的均值。 
x = x - repmat(avg, size(x, 1), 1);

```

下面，我们要计算 ![\textstyle \Sigma = \frac{1}{m} \sum_{i=1}^m (x^{(i)})(x^{(i)})^T](images/math/f/1/2/f12024bb76487f8a050f92a84b09278c.png) ，如果你在Matlab中实现（或者在C++, Java等中实现，但可以使用高效的线性代数库），直接求和效率很低。不过，我们可以这样一气呵成。

```
sigma = x * x' / size(x, 2);

```

（自己推导一下看看）这里，我们假设 *x* 为一数据结构，其中每列表示一个训练样本（所以 *x* 是一个 ![\textstyle n](images/math/0/c/5/0c59de0fa75c1baa1c024aabfa43b2e3.png)×![\textstyle m](images/math/2/5/e/25e97e8a905fc2cb05d76cd4872a8567.png) 的矩阵）。

接下来，PCA计算 Σ 的特征向量。你可以使用Matlab的 eig 函数来计算。但是由于 Σ 是对称半正定的矩阵，用 svd 函数在数值计算上更加稳定。

具体来说，如果你使用

```
[U,S,V] = svd(sigma);

```

那矩阵 *U* 将包含 *S**i**g**m**a* 的特征向量（一个特征向量一列，从主向量开始排序），矩阵S 对角线上的元素将包含对应的特征值（同样降序排列）。矩阵 ![\textstyle V](images/math/0/b/6/0b6f6c0f23cf3b29f3652c7315c456aa.png) 等于 ![\textstyle U](images/math/6/a/5/6a55fb16b0464ccd6652a7f2a583217f.png) 的转置，可以忽略。

（注意 svd 函数实际上计算的是一个矩阵的奇异值和奇异向量，就对称半正定矩阵的特殊情况来说，它们对应于特征值和特征向量，这里我们也只关心这一特例。关于奇异向量和特征向量的详细讨论超出了本文范围。）

最后，我们可以这样计 算![\textstyle x_{\rm rot}](images/math/1/7/0/170047e804738636731477291969d554.png) 和 ![\textstyle \tilde{x}](images/math/1/a/6/1a62e33dcf57261829692126a4dcd02d.png) ：

```
xRot = U' * x;          % 数据旋转后的结果。 
xTilde = U(:,1:k)' * x; % 数据降维后的结果，这里k希望保留的特征向量的数目。

```

这以 ![\textstyle \tilde{x} \in \Re^k](images/math/2/1/3/21337248295f42f7fe18d9a9b3da57b1.png) 的形式给出了数据的PCA表示。顺便说一下，如果 *x* 是一个包括所有训练数据的 ![\textstyle n](images/math/0/c/5/0c59de0fa75c1baa1c024aabfa43b2e3.png)×![\textstyle m](images/math/2/5/e/25e97e8a905fc2cb05d76cd4872a8567.png) 矩阵，这也是一种向量化的实现方式，上面的式子可以让你一次对所有的训练样本计算出 *x*rot 和 ![\tilde{x}](images/math/5/1/8/51883bb93a4ebf4069a08b311c8bed76.png) 。得到的 *x*rot 和 ![\tilde{x}](images/math/5/1/8/51883bb93a4ebf4069a08b311c8bed76.png) 中，每列对应一个训练样本。

为计算PCA白化后的数据 ![\textstyle x_{\rm PCAwhite}](images/math/c/9/a/c9a6829ec8736d78ef1fb62a77564b53.png) ，可以用

```
xPCAwhite = diag(1./sqrt(diag(S) + epsilon)) * U' * x;

```

因为 *S* 的对角线包括了特征值 ![\textstyle \lambda_i](images/math/2/3/5/23536ce45f0ee57fffa389163f8437bd.png) ，这其实就是同时为所有样本![\textstyle i](images/math/0/b/3/0b36ee693126b34b58f77dba7ed23987.png)计算 ![\textstyle x_{{\rm PCAwhite},i} = \frac{x_{{\rm rot},i} }{\sqrt{\lambda_i}}](images/math/4/a/0/4a0f44026d3d8598a69070eb52e64698.png) 的简洁表达。

最后，你也可以这样计算ZCA白化后的数据![\textstyle x_{\rm ZCAwhite}](images/math/a/6/6/a668553308d25ae0f796a9f92c807931.png):

```
xZCAwhite = U * diag(1./sqrt(diag(S) + epsilon)) * U' * x;

```

 中英文对照
------

主成分分析 Principal Components Analysis (PCA)
白化 whitening
均值为零 zero-mean
均值 mean value
特征值 eigenvalue
特征向量 eigenvector
对称半正定矩阵 symmetric positive semi-definite matrix
数值计算上稳定 numerically reliable
降序排列 sorted in decreasing order
奇异值 singular value
奇异向量 singular vector
向量化实现 vectorized implementation
对角线 diagonal

 中文译者
-----

周思远（visualzhou@gmail.com），张力（emma.lzhang@gmail.com），谭晓阳（x.tan@nuaa.edu.cn）

[主成分分析](%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90.md "主成分分析") | [白化](%E7%99%BD%E5%8C%96.md "白化") | **实现主成分分析和白化** | [Exercise:PCA in 2D](Exercise_PCA_in_2D.md "Exercise:PCA in 2D") | [Exercise:PCA and Whitening](Exercise_PCA_and_Whitening.md "Exercise:PCA and Whitening")

---

> * Language: [English](/wayback-mooc/stanford-ufldl/wiki/Implementing_PCA/Whitening "Implementing PCA/Whitening")
> * This page was last modified on 8 April 2013, at 05:38.

